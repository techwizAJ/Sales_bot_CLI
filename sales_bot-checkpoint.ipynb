{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Fri Nov 30 15:27:41 2018\n",
    "@author: arihant\n",
    "\n",
    "# SALES BOT  DEVELOPMENT \n",
    "\n",
    "# Example Queries to be addressed \n",
    "    Sales for today \n",
    "    Sales for week\n",
    "    Sales for month  or for any number of days\n",
    "    Sales for any mentioned article or brands  or category\n",
    "    Top articles or brands sold in week ,month..\n",
    "\n",
    "# Considering Today as 31 AUG,2008 according to data given\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function For Sales Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salesInfo(df , date , brand= None, category = None):\n",
    "    start, end = date, datetime.datetime(2018, 8, 31, 0, 0)\n",
    "    df = df[ (df['sale_date'] >= start) &  (df['sale_date'] <= end) ] \n",
    "    if brand is not None:\n",
    "        df = df[ (df['brand_name']==brand) ]\n",
    "        return df['total_price'].sum()\n",
    "    if category is not None:\n",
    "        df = df[ (df['category_name']==category) ]\n",
    "        return df['total_price'].sum()\n",
    "    return df['total_price'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Top product articles brands sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TopSalesInfo(df, date, brand = False, article =False):\n",
    "    start, end = date, datetime.datetime(2018, 8, 31, 0, 0)\n",
    "    df = df[ (df['sale_date'] >= start) &  (df['sale_date'] <= end) ] \n",
    "    if article:\n",
    "        df2 = df[['id','name','total_price']]\n",
    "        df2 = df2.groupby(['id', 'name']).sum()\n",
    "        return df2.head()\n",
    "    else:\n",
    "        df2 = df[['id','brand_name','total_price']]\n",
    "        df2 = df2.groupby(['id', 'brand_name']).sum()\n",
    "        return df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getEntity_date(text):\n",
    "    entities = { 'today':0 , 'yesterday':1 , 'week':7, 'month':30 }\n",
    "    for w in entities:\n",
    "        if w in text:\n",
    "            loc = entities[w]\n",
    "            t = datetime.datetime(2018, 8, 31-loc, 0, 0)\n",
    "            return t\n",
    "    return None\n",
    "def entity_def(text):\n",
    "    entities = ['sale','top']\n",
    "    for w in entities:\n",
    "        if w in text:\n",
    "            loc = text.index(w)\n",
    "            return text[loc]\n",
    "    return None\n",
    "def entity_type(text):\n",
    "    entities =['article','brand']\n",
    "    for w in entities:\n",
    "        if w in text:\n",
    "            loc = entities.index(w)\n",
    "            print(loc)\n",
    "            return True if loc == 0 else False\n",
    "    return None\n",
    "def entity_brand(text,df):\n",
    "    brands = df['brand_name'].unique()\n",
    "    for w in brands:\n",
    "        if w in text:\n",
    "            return w\n",
    "    return None\n",
    "def entity_category(text,df):\n",
    "    category = df['category_name'].unique()\n",
    "    for w in category:\n",
    "        if w in text:\n",
    "            return w\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def response(df,def_type,date,types,brand,category):\n",
    "    if def_type == 'sale':\n",
    "        print('RS',salesInfo(df,date,brand,category))\n",
    "    else:\n",
    "        if types:\n",
    "            print(TopSalesInfo(df,date,article =True))\n",
    "        else:\n",
    "            print(TopSalesInfo(df,date,brand =True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data in Pandas DataFrames \n",
    "Combining table details to one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = pd.read_csv('articles.csv')\n",
    "train_bills = pd.read_csv('bills.csv')\n",
    "hr = pd.read_csv('hierarchy.csv')\n",
    "df = pd.merge(train_bills, hr, left_on='article_id', right_on='article_id', how='left')\n",
    "df = pd.merge( df,articles ,left_on='article_id' , right_on='id' , how='left')\n",
    "df['sale_date'] = pd.to_datetime(df['sale_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ending responses and pause responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_greetings =[ 'bye' , 'goodbye','see you later','talk to you later','tada']\n",
    "Pause_greet = ['Having some trouble looking at database' , 'Contact DB admin', 'Come again']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing bot\n",
    "# Used NLTK to fliter input to words using word tokenizer                                \n",
    "# Used NLTK to filter input by removing stop words                                           \n",
    "# Used NLTK to filter input by lemmatizing word to root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Speak to Sales Bot: sales for today\n",
      "RS 28550.80250000002\n",
      ">>Speak to Sales Bot: sales of nestle this month\n",
      "RS 3239.2974999999983\n",
      ">>Speak to Sales Bot: sales of godrej this week\n",
      "RS 2238.0003999999994\n",
      ">>Speak to Sales Bot: sales of rin today\n",
      "RS 307.3008\n",
      ">>Speak to Sales Bot: top articles sold this week\n",
      "0\n",
      "                                                 total_price\n",
      "id  name                                                    \n",
      "89  rin bar 150g rs.10                             1054.7812\n",
      "149 parle hide&seek chocolate chip cookies 120g    1035.7200\n",
      "308 sabena 450g                                     629.4600\n",
      "375 britannia marie gold biscuits rs.22             711.6000\n",
      "404 britannia 50-50 maska chaska biscuits rs.10     390.6598\n",
      ">>Speak to Sales Bot: top brands sold this month\n",
      "1\n",
      "                total_price\n",
      "id  brand_name             \n",
      "89  rin           5074.5836\n",
      "149 parle         3600.4000\n",
      "308 sabena        3304.8993\n",
      "375 britannia     4082.0598\n",
      "404 britannia     2848.5995\n",
      ">>Speak to Sales Bot: sales of detergents this week\n",
      "RS 5004.061900000009\n",
      ">>Speak to Sales Bot: bye\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "while (flag==True):\n",
    "    text = input('>>Speak to Sales Bot: ')\n",
    "    text = text.lower()\n",
    "    if ( text in close_greetings):\n",
    "        flag= False\n",
    "    # Removing stop words and Lemmatization using NLTK\n",
    "    stop_words = set(stopwords.words(\"English\"))\n",
    "    words = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    fliter_sentence = []\n",
    "    for w in words:\n",
    "    \tif w not in stop_words:\n",
    "            fliter_sentence.append(lemmatizer.lemmatize(w))\n",
    "    #Getting entity information   \n",
    "    entity_date = getEntity_date(fliter_sentence)\n",
    "    entitydef = entity_def(fliter_sentence)\n",
    "    entitytype = entity_type(fliter_sentence)\n",
    "    entitybrand = entity_brand(text,df)\n",
    "    entitycategory = entity_category(text,df)\n",
    "    if ( entitydef is None):\n",
    "        random.choice(Pause_greet)\n",
    "        break\n",
    "    # response\n",
    "    response(df,entitydef,entity_date,entitytype,entitybrand,entitycategory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
